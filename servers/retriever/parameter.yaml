# servers/retriever/parameter.yaml

model_name_or_path: openbmb/MiniCPM-Embedding-Light
corpus_path: data/corpus_example.jsonl
embedding_path: embedding/embedding.npy

backend: sentence_transformers # options: infinity, sentence_transformers, openai, bm25
backend_configs:
  infinity:
    bettertransformer: false
    pooling_method: auto
    device: cuda
    model_warmup: false
    trust_remote_code: true
  sentence_transformers:
    device: cuda
    trust_remote_code: true
    sentence_transformers_encode:
      normalize_embeddings: false
      encode_chunk_size: 10000
      q_prompt_name: query
      psg_prompt_name: document
      psg_task: null
      q_task: null
  openai:
    model_name: text-embedding-3-small
    base_url: "https://api.openai.com/v1"
    api_key: ""
  bm25:
    lang: en
    save_path: index/bm25

index_backend: faiss # options: faiss, milvus
index_backend_configs:
  faiss:
    index_use_gpu: True
    index_chunk_size: 50000
    index_path: index/index.index
  milvus:
    uri: index/milvus_demo.db # Milvus Lite local file (or http://localhost:19530 for server)
    token: null
    collection_name: ultrarag_embeddings
    id_field_name: id
    vector_field_name: vector
    metric_type: IP
    index_params:
      index_type: AUTOINDEX
      metric_type: IP
    search_params:
      metric_type: IP
      params: {}
    index_chunk_size: 50000

batch_size: 16
top_k: 5
gpu_ids: "0,1"
query_instruction: ""
is_multimodal: false
overwrite: false
retrieve_thread_num: 1
